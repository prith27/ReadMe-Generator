{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56cc062f-4e3b-4cad-9bbd-9c33f8be4d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import requests\n",
    "import os\n",
    "from github import Github\n",
    "from github import GithubException\n",
    "import openai\n",
    "from pathlib import Path\n",
    "import base64\n",
    "import tiktoken\n",
    "import time\n",
    "from typing import Dict, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b945da52-50e8-40bf-b798-92cd443b834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI client\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# Initialize GitHub client\n",
    "github_token = os.getenv(\"GITHUB_TOKEN\")\n",
    "g = Github(github_token) if github_token else Github()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8834091-3a7c-431f-8c52-2aee3832f46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(text: str) -> int:\n",
    "    \"\"\"Count tokens in text using GPT-4 tokenizer.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "    return len(encoding.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1b4196a-e39a-42f3-9878-556f31321af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repo_contents(repo_url: str) -> Tuple[bool, Dict]:\n",
    "    \"\"\"\n",
    "    Fetch repository contents and check if it's public.\n",
    "    Returns (is_public, content_dict)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract owner and repo name from URL\n",
    "        parts = repo_url.rstrip('/').split('/')\n",
    "        owner, repo_name = parts[-2], parts[-1]\n",
    "        \n",
    "        # Try to get repository\n",
    "        repo = g.get_repo(f\"{owner}/{repo_name}\")\n",
    "        \n",
    "        # Get main branch\n",
    "        default_branch = repo.default_branch\n",
    "        \n",
    "        # Get contents\n",
    "        contents = {}\n",
    "        max_files = 20  # Limit number of files to process\n",
    "        file_count = 0\n",
    "        \n",
    "        def process_contents(path=\"\"):\n",
    "            nonlocal file_count\n",
    "            if file_count >= max_files:\n",
    "                return\n",
    "            \n",
    "            items = repo.get_contents(path)\n",
    "            for item in items:\n",
    "                if file_count >= max_files:\n",
    "                    break\n",
    "                    \n",
    "                if item.type == \"dir\":\n",
    "                    process_contents(item.path)\n",
    "                else:\n",
    "                    # Skip binary files and very large files\n",
    "                    if item.size > 100000 or any(item.name.endswith(ext) for ext in ['.png', '.jpg', '.jpeg', '.gif', '.pdf']):\n",
    "                        continue\n",
    "                        \n",
    "                    try:\n",
    "                        content = base64.b64decode(item.content).decode('utf-8')\n",
    "                        contents[item.path] = {\n",
    "                            'content': content,\n",
    "                            'size': item.size,\n",
    "                            'type': item.type\n",
    "                        }\n",
    "                        file_count += 1\n",
    "                    except Exception:\n",
    "                        continue\n",
    "        \n",
    "        process_contents()\n",
    "        return True, contents\n",
    "        \n",
    "    except GithubException as e:\n",
    "        if e.status == 404:\n",
    "            return False, {\"error\": \"Repository not found or private\"}\n",
    "        return False, {\"error\": f\"GitHub API error: {str(e)}\"}\n",
    "    except Exception as e:\n",
    "        return False, {\"error\": f\"Unexpected error: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69f61f6c-dd43-44ad-ae83-0a9a281be981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_readme(repo_contents: Dict) -> str:\n",
    "    \"\"\"Generate README using GPT-4.\"\"\"\n",
    "    \n",
    "    # Prepare context for GPT-4\n",
    "    context = \"Repository contents:\\n\\n\"\n",
    "    total_tokens = 0\n",
    "    max_tokens = 6000  # Leave room for response\n",
    "    \n",
    "    for path, info in repo_contents.items():\n",
    "        file_preview = info['content'][:1000] + \"...\" if len(info['content']) > 1000 else info['content']\n",
    "        file_context = f\"File: {path}\\n{file_preview}\\n\\n\"\n",
    "        file_tokens = count_tokens(file_context)\n",
    "        \n",
    "        if total_tokens + file_tokens > max_tokens:\n",
    "            break\n",
    "            \n",
    "        context += file_context\n",
    "        total_tokens += file_tokens\n",
    "\n",
    "    try:\n",
    "        prompt = f\"\"\"Based on the following repository contents, generate a comprehensive README.md file. \n",
    "        Include sections for:\n",
    "        - Project title and description\n",
    "        - Features\n",
    "        - Installation instructions\n",
    "        - Usage examples\n",
    "        - Project structure\n",
    "        - Dependencies\n",
    "        - Contributing guidelines (if applicable)\n",
    "        - License information (if found)\n",
    "\n",
    "        Format the output in proper Markdown.\n",
    "\n",
    "        {context}\"\"\"\n",
    "\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a technical writer specialized in creating clear, comprehensive README files for software projects.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=2000,\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content\n",
    "        \n",
    "    except openai.error.RateLimitError:\n",
    "        return \"Error: OpenAI API rate limit exceeded. Please try again later.\"\n",
    "    except openai.error.InvalidRequestError as e:\n",
    "        return f\"Error: Invalid request to OpenAI API: {str(e)}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error generating README: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f71b2874-58a7-4e92-a47e-8519a1fa456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_repository(repo_url: str, progress=gr.Progress()) -> str:\n",
    "    \"\"\"Main function to process repository and generate README.\"\"\"\n",
    "    \n",
    "    if not repo_url or not repo_url.startswith(\"https://github.com/\"):\n",
    "        return \"# Error\\n---\\nPlease enter a valid GitHub repository URL\"\n",
    "    \n",
    "    progress(0.1, desc=\"Validating repository URL...\")\n",
    "    \n",
    "    is_public, contents = get_repo_contents(repo_url)\n",
    "    \n",
    "    if not is_public:\n",
    "        return f\"# Error\\n---\\n{contents.get('error', 'Unknown error')}\"\n",
    "    \n",
    "    progress(0.4, desc=\"Analyzing repository contents...\")\n",
    "    \n",
    "    if not contents:\n",
    "        return \"# Error\\n---\\nNo readable contents found in repository\"\n",
    "    \n",
    "    progress(0.7, desc=\"Generating README with GPT-4...\")\n",
    "    readme = generate_readme(contents)\n",
    "    \n",
    "    progress(1.0, desc=\"Done!\")\n",
    "    return readme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4ca15a6-6941-4b56-bd4d-9c80a72fdea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interface():\n",
    "    with gr.Blocks(theme=gr.themes.Soft()) as interface:\n",
    "        gr.Markdown(\"# üìö GitHub README Generator\")\n",
    "        gr.Markdown(\"Enter a public GitHub repository URL to generate a comprehensive README.md file.\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=1):\n",
    "                repo_url = gr.Textbox(\n",
    "                    label=\"GitHub Repository URL\",\n",
    "                    placeholder=\"https://github.com/username/repository\"\n",
    "                )\n",
    "                generate_btn = gr.Button(\"üîÆ Generate README\", variant=\"primary\")\n",
    "                \n",
    "                gr.Markdown(\"\"\"\n",
    "                ### üìù Notes:\n",
    "                - Only public repositories are supported\n",
    "                - Maximum 20 files will be processed per repository\n",
    "                - Large files and binary files are skipped\n",
    "                - The tool uses GPT-4 for README generation\n",
    "                \"\"\")\n",
    "            \n",
    "            with gr.Column(scale=2):\n",
    "                # Modified Markdown component configuration\n",
    "                output = gr.Markdown(\n",
    "                    value=\"Your generated README will appear here...\",\n",
    "                    container=True\n",
    "                )\n",
    "        \n",
    "        generate_btn.click(\n",
    "            fn=process_repository,\n",
    "            inputs=[repo_url],\n",
    "            outputs=[output],\n",
    "            show_progress=True\n",
    "        )\n",
    "    \n",
    "    return interface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3f88458-09c2-4071-88fa-51f0039d04ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create and launch the interface\n",
    "if __name__ == \"__main__\":\n",
    "    interface = create_interface()\n",
    "    interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff7c476-7135-45c4-a316-2184638476a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
